🚀 Experimente e descubra qual LLM entrega as melhores respostas para suas perguntas!
# LLM-Compare

## Introdução ao Projeto:
O LLM Compare é uma aplicação que acessa e compara respostas geradas por pelos Modelos de Linguagem de Grande Escala (LLMs) GEMINI, MISTRAL, ANTHROPIC. O objetivo é fornecer uma análise comparativa da qualidade das respostas para uma mesma pergunta, permitindo avaliar pontos fortes e limitações de cada modelo.

## Critérios de Avaliação

As respostas dos modelos são analisadas com base em três critérios principais:

* 1️⃣ Precisão da Informação – A resposta apresenta informações corretas e sem erros? Há omissões ou inconsistências? 
* 2️⃣ Clareza e Coerência – A resposta é direta, compreensível e bem estruturada?
* 3️⃣ Criatividade ou Profundidade – A resposta adiciona contexto interessante, curiosidades ou explicações adicionais que enriquecem a resposta?

Cada critério recebe uma nota de 0 a 10, e o modelo com a maior média de pontuação é destacado como o melhor para aquela pergunta específica.

A avaliação é feita automaticamente por outro modelo de IA, garantindo uma análise imparcial entre as respostas dos concorrentes.


## 🛠️ Tecnologias utilizadas

* Python
* VScode
  
## 📋 Inicializando a aplicação

* [Samuel Oliveira](https://github.com/SamuelOliveira-M)* - *Desenvolvedor*
